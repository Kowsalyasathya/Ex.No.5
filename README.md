

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim:
To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

# AI Tools Required: 

ChatGPT (GPT-based model) or equivalent AI tool

Laptop/PC with internet connection

# OUTPUT

The experiment was carried out using two types of prompts: Naïve (unstructured) and Basic (structured/refined).

For each selected scenario (story generation, factual question answering, summarization, and career advice), ChatGPT generated responses.

Observation of Outputs:

Story Generation: The naïve prompt gave a simple generic story, while the basic prompt produced a motivational, context-driven story involving AI and IoT.

Factual Question: The naïve prompt gave only a basic definition of AI, whereas the basic prompt explained AI with functions and real-world applications.

Summarization: The naïve prompt generated a long paragraph, while the basic prompt provided clear, concise bullet points covering causes, effects, and responses.

Advice/Recommendation: The naïve prompt gave general advice like “work hard,” but the basic prompt provided practical, career-specific guidance (skills, projects, internships).

Across all scenarios, the basic prompts consistently generated more accurate, structured, and deeper outputs than naïve prompts.

### Explanation:

Naïve Prompt: Broad, vague, or unstructured queries.

Basic Prompt: Clear, detailed, and structured queries with specific context.

By applying both types of prompts across multiple scenarios, we can compare the effectiveness of prompt clarity on AI outputs.

Test Scenarios

Creative Story Generation

Naïve Prompt: “Write a story.”

Basic Prompt: “Write a short story about a young engineer who uses AI and IoT to improve farming in a small village. The story should be motivational and highlight the role of technology.”

Factual Question

Naïve Prompt: “What is AI?”

Basic Prompt: “Explain Artificial Intelligence in 4–5 sentences, highlighting its definition, core functions, and real-world applications in healthcare and manufacturing.”

Summarization

Naïve Prompt: “Summarize climate change.”

Basic Prompt: “Summarize the concept of climate change in less than 5 bullet points, covering causes, effects, and global responses.”

Advice/Recommendation

Naïve Prompt: “Give me career advice.”

Basic Prompt: “Provide career advice for a data science student in their final year of college, focusing on skills to develop, internships to pursue, and projects to build for better job opportunities.”

Comparative Analysis

Creative Story:

Naïve → Generic and random story.

Basic → Motivational story with AI & IoT, relevant to context.

Factual Question:

Naïve → Simple definition only.

Basic → Detailed explanation + examples in healthcare and manufacturing.

### Summarization:

Naïve → Long unstructured paragraph.

Basic → Concise bullet points with clear categories.

Advice/Recommendation:

Naïve → Generic advice like “work hard.”

Basic → Practical advice (Python, ML, SQL skills, internships, projects).

Findings

Quality: Basic prompts produced structured and clear outputs.

Accuracy: Specific prompts reduced vagueness and improved factual correctness.

Depth: Detailed prompts gave more targeted and valuable insights.

Observation: In very simple questions, naïve prompts still gave usable answers, but lacked detail and relevance.

# RESULT: 
The prompt for the above said problem executed successfully
